{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # run once only\n",
    "# os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelInferenceConfig:\n",
    "    \"\"\"\n",
    "    Data class for storing model inference configuration.\n",
    "\n",
    "    Attributes:\n",
    "        registered_model_name (str): The name of the registered model.\n",
    "        version (int): The version number of the model.\n",
    "    \"\"\"\n",
    "    registered_model_name: str\n",
    "    version: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/config/configuration_manager.py\n",
    "from src.utils.common import read_yaml, create_directories\n",
    "class ConfigurationManager:\n",
    "    \"\"\"\n",
    "    Prepare ConfigurationManager class.\n",
    "    \n",
    "    This class is responsible for reading configuration files and preparing\n",
    "    configuration settings for the pipeline.\n",
    "\n",
    "    Attributes:\n",
    "        config (dict): Parsed configuration file content.\n",
    "        params (dict): Parsed parameters file content.\n",
    "        schema (dict): Parsed schema file content.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath: str = CONFIG_FILE_PATH, \n",
    "        params_filepath: str = PARAMS_FILE_PATH, \n",
    "        schema_filepath: str = SCHEMA_FILE_PATH\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the ConfigurationManager with file paths.\n",
    "\n",
    "        Args:\n",
    "            config_filepath (str): File path to the configuration YAML file.\n",
    "            params_filepath (str): File path to the parameters YAML file.\n",
    "            schema_filepath (str): File path to the schema YAML file.\n",
    "        \"\"\"\n",
    "        self.config = read_yaml(Path(config_filepath))\n",
    "        self.params = read_yaml(Path(params_filepath))\n",
    "        self.schema = read_yaml(Path(schema_filepath))\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_inference_config(self) -> ModelInferenceConfig:\n",
    "        \"\"\"\n",
    "        Get configuration for model inference.\n",
    "        \n",
    "        Returns:\n",
    "            ModelInferenceConfig: Configuration for model inference.\n",
    "        \"\"\"\n",
    "        config = self.config.model_inference\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_inference_config = ModelInferenceConfig(\n",
    "            registered_model_name=config.mlflow.registered_model_name,\n",
    "            version=config.mlflow.version,\n",
    "        )\n",
    "        return model_inference_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-11 09:07:11,715 - credit-scorecard-logger - INFO - yaml file: config.yaml loaded successfully\n",
      "2024-06-11 09:07:11,715 - credit-scorecard-logger - INFO - yaml file: params.yaml loaded successfully\n",
      "2024-06-11 09:07:11,729 - credit-scorecard-logger - INFO - yaml file: schema.yaml loaded successfully\n",
      "2024-06-11 09:07:11,729 - credit-scorecard-logger - INFO - Created directory at: artifacts\n",
      "2024-06-11 09:07:11,729 - credit-scorecard-logger - INFO - Created directory at: models/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModelInferenceConfig(registered_model_name='credit-score-model', version=1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration_manager = ConfigurationManager()\n",
    "configuration_manager.get_model_inference_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up environment variables:\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Union\n",
    "from src.utils.common import logger\n",
    "# from src.entities.config_entity import ModelInferenceConfig\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "\n",
    "class ModelInference:\n",
    "    \"\"\"\n",
    "    A class used to perform model inference using a pre-trained model.\n",
    "\n",
    "    This class is responsible for loading a model from a specified path and\n",
    "    providing methods to make predictions on input data.\n",
    "\n",
    "    Attributes:\n",
    "        config (ModelInferenceConfig): Configuration for model inference.\n",
    "        model: The loaded machine learning model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: ModelInferenceConfig):\n",
    "        \"\"\"\n",
    "        Initialize the ModelInference with a configuration.\n",
    "\n",
    "        Args:\n",
    "            config (ModelInferenceConfig): The configuration containing paths for model inference.\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.model = self.get_model(self.config.registered_model_name, self.config.version)\n",
    "\n",
    "    def get_model(self, model_name: str, version: int) -> BaseEstimator:\n",
    "        try:\n",
    "            mlflow.set_tracking_uri(os.getenv('MLFLOW_TRACKING_URI'))\n",
    "            model = mlflow.sklearn.load_model(f\"models:/{model_name}/{version}\")\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            logger.error(e) \n",
    "\n",
    "    def predict(self, data: Union[pd.DataFrame, np.ndarray, np.array]) -> np.array:\n",
    "        \"\"\"\n",
    "        Make predictions on input data.\n",
    "\n",
    "        Args:\n",
    "            data Union[pd.DataFrame, np.ndarray, np.array]: Preprocessed input data for which predictions are to be made.\n",
    "\n",
    "        Returns:\n",
    "            np.array: The predicted values.\n",
    "        \"\"\"\n",
    "        logger.info(\"Predict\")\n",
    "        prediction = self.model.predict(data)\n",
    "        return prediction\n",
    "\n",
    "    def predict_proba(\n",
    "        self, data: Union[pd.DataFrame, np.ndarray, np.array]\n",
    "    ) -> np.array:\n",
    "        \"\"\"\n",
    "        Make probability predictions on input data.\n",
    "\n",
    "        Args:\n",
    "            data Union[pd.DataFrame, np.ndarray, np.array]: Preprocessed input data for which probability predictions are to be made.\n",
    "\n",
    "        Returns:\n",
    "            np.array: The predicted probabilities.\n",
    "        \"\"\"\n",
    "        logger.info(\"Predict probabilities\")\n",
    "        prediction = self.model.predict_proba(data)\n",
    "        return prediction[:, -1]\n",
    "    \n",
    "    def score(\n",
    "        self, data: Union[pd.DataFrame, np.ndarray, np.array]\n",
    "    ) -> np.array:\n",
    "        \"\"\"\n",
    "        Give credit scores on input data.\n",
    "\n",
    "        Args:\n",
    "            data Union[pd.DataFrame, np.ndarray, np.array]: Preprocessed input data for which credit scores are to be made.\n",
    "\n",
    "        Returns:\n",
    "            np.array: The credit scores.\n",
    "        \"\"\"\n",
    "        logger.info(\"Get credit score\")\n",
    "        prediction = self.model.score(data)\n",
    "        return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-11 09:10:10,447 - credit-scorecard-logger - INFO - yaml file: config.yaml loaded successfully\n",
      "2024-06-11 09:10:10,447 - credit-scorecard-logger - INFO - yaml file: params.yaml loaded successfully\n",
      "2024-06-11 09:10:10,447 - credit-scorecard-logger - INFO - yaml file: schema.yaml loaded successfully\n",
      "2024-06-11 09:10:10,447 - credit-scorecard-logger - INFO - Created directory at: artifacts\n",
      "2024-06-11 09:10:10,447 - credit-scorecard-logger - INFO - Created directory at: models/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 9/9 [00:00<00:00, 17.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-11 09:10:12,553 - credit-scorecard-logger - INFO - Predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    configuration_manager = ConfigurationManager()\n",
    "    model_inference = ModelInference(configuration_manager.get_model_inference_config())\n",
    "    test = pd.read_csv(\"artifacts/data_preprocessing/test.csv\")\n",
    "    X_test, y_test = test.drop(columns=['loan_status']), test['loan_status']\n",
    "    display(model_inference.predict(X_test))\n",
    "except Exception as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "# get last experiment id\n",
    "mlflow.set_tracking_uri(os.getenv('MLFLOW_TRACKING_URI'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-11 08:59:10,177 - credit-scorecard-logger - INFO - yaml file: config.yaml loaded successfully\n",
      "2024-06-11 08:59:10,197 - credit-scorecard-logger - INFO - yaml file: params.yaml loaded successfully\n",
      "2024-06-11 08:59:10,197 - credit-scorecard-logger - INFO - yaml file: schema.yaml loaded successfully\n",
      "2024-06-11 08:59:10,197 - credit-scorecard-logger - INFO - Created directory at: artifacts\n",
      "2024-06-11 08:59:10,197 - credit-scorecard-logger - INFO - Created directory at: models/\n"
     ]
    }
   ],
   "source": [
    "configuration_manager = ConfigurationManager()\n",
    "inference_config = configuration_manager.get_model_inference_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 9/9 [00:00<00:00, 15.97it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([572.08448915, 583.40533029, 625.106093  , ..., 577.6666715 ,\n",
       "       556.21258813, 600.6620341 ])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model:\n",
    "model = load_model(inference_config.registered_model_name, inference_config.version)\n",
    "\n",
    "# Test model:\n",
    "test = pd.read_csv(\"artifacts/data_preprocessing/test.csv\")\n",
    "X_test, y_test = test.drop(columns=['loan_status']), test['loan_status']\n",
    "model.score(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'person_age': 22,\n",
       " 'person_income': 50000,\n",
       " 'person_home_ownership': 'RENT',\n",
       " 'person_emp_length': 6.0,\n",
       " 'loan_intent': 'PERSONAL',\n",
       " 'loan_grade': 'B',\n",
       " 'loan_amnt': 6000,\n",
       " 'loan_int_rate': 11.89,\n",
       " 'loan_percent_income': 0.12,\n",
       " 'cb_person_default_on_file': 'N',\n",
       " 'cb_person_cred_hist_length': 2}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[0].to_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Test\n",
    "The API script is developed using FastAPI and it is available in `app.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [500]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "ENDPOINT=\"http://127.0.0.1:8000/credit-score\"\n",
    "input = {\n",
    "    'person_age': 22,\n",
    "    'person_income': 50000,\n",
    "    'person_home_ownership': 'RENT',\n",
    "    'person_emp_length': 6.0,\n",
    "    'loan_intent': 'PERSONAL',\n",
    "    'loan_grade': 'B',\n",
    "    'loan_amnt': 6000,\n",
    "    'loan_int_rate': 11.89,\n",
    "    'loan_percent_income': 0.12,\n",
    "    'cb_person_default_on_file': 'N',\n",
    "    'cb_person_cred_hist_length': 2\n",
    "}\n",
    "prediction = requests.post(\n",
    "    url=ENDPOINT,\n",
    "    json=input,\n",
    "    headers={\"Content-Type\": \"application/json\"}\n",
    ")\n",
    "\n",
    "prediction #.json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "risk-modelling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
