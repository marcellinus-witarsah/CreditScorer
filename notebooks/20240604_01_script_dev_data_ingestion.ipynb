{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion Pipeline Development\n",
    "- Author: Marcellinus Aditya Witarsah\n",
    "- Date: 05 June 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import logging\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "from pathlib import Path\n",
    "from abc import ABC\n",
    "from abc import abstractmethod\n",
    "from scipy import stats\n",
    "from typing import Tuple\n",
    "from typing import Union\n",
    "from dataclasses import dataclass\n",
    "from src.utils.common import logger\n",
    "from src.utils.common import read_yaml, create_directories\n",
    "from src.constants import CONFIG_FILE_PATH, SCHEMA_FILE_PATH, PARAMS_FILE_PATH\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # run once only\n",
    "# os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/entities/config_entity.py\n",
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    \"\"\"\n",
    "    Data class for storing data ingestion configuration.\n",
    "\n",
    "    Attributes:\n",
    "        root_dir (Path): Root directory for data ingestion.\n",
    "        source_path (Path): Source path of the data.\n",
    "        target_path (Path): Target path for the processed data.\n",
    "    \"\"\"\n",
    "    root_dir: Path\n",
    "    source_path: Path\n",
    "    target_path: Path\n",
    "\n",
    "# src/config/configuration_manager.py\n",
    "class ConfigurationManager:\n",
    "    \"\"\"\n",
    "    Prepare ConfigurationManager class.\n",
    "    \n",
    "    This class is responsible for reading configuration files and preparing\n",
    "    configuration settings for the pipeline.\n",
    "\n",
    "    Attributes:\n",
    "        config (dict): Parsed configuration file content.\n",
    "        params (dict): Parsed parameters file content.\n",
    "        schema (dict): Parsed schema file content.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath: str = CONFIG_FILE_PATH, \n",
    "        params_filepath: str = PARAMS_FILE_PATH, \n",
    "        schema_filepath: str = SCHEMA_FILE_PATH\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the ConfigurationManager with file paths.\n",
    "\n",
    "        Args:\n",
    "            config_filepath (str): File path to the configuration YAML file.\n",
    "            params_filepath (str): File path to the parameters YAML file.\n",
    "            schema_filepath (str): File path to the schema YAML file.\n",
    "        \"\"\"\n",
    "        self.config = read_yaml(Path(config_filepath))\n",
    "        self.params = read_yaml(Path(params_filepath))\n",
    "        self.schema = read_yaml(Path(schema_filepath))\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "        \"\"\"\n",
    "        Get configuration for data ingestion.\n",
    "        \n",
    "        Returns:\n",
    "            DataIngestionConfig: Configuration for data ingestion.\n",
    "        \"\"\"\n",
    "        config = self.config.get('data_ingestion', {})\n",
    "        \n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            source_path=Path(config.source_path),\n",
    "            target_path=Path(config.target_path),\n",
    "        )\n",
    "        return data_ingestion_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/data/data_ingestion.py\n",
    "class DataIngestionStrategy(ABC):\n",
    "    \"\"\"\n",
    "    Abstract base class for data ingestion strategies.\n",
    "    \"\"\"\n",
    "    @abstractmethod\n",
    "    def ingest_data(self, paths: list, target_path: Path) -> None:\n",
    "        \"\"\"\n",
    "        Ingests data from the specified paths to the target path.\n",
    "\n",
    "        Args:\n",
    "            paths (list): List of file paths to ingest data from.\n",
    "            target_path (Path): Path to save the ingested data.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "# src/data/data_ingestion.py\n",
    "class PandasDataIngestionStrategy(DataIngestionStrategy):\n",
    "    \"\"\"\n",
    "    Data ingestion strategy using Pandas.\n",
    "    \"\"\"\n",
    "    def ingest_data(self, paths: list, target_path: Path) -> None:\n",
    "        \"\"\"\n",
    "        Ingests data using Pandas.\n",
    "\n",
    "        Args:\n",
    "            paths (list): List of file paths to ingest data from.\n",
    "            target_path (Path): Path to save the ingested data.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        df = pd.DataFrame({})\n",
    "\n",
    "        # Read and concatenate dataframes (if more than one):\n",
    "        for path in paths:\n",
    "            path = Path(path)\n",
    "            start = time.perf_counter()\n",
    "            if path.suffix == \".csv\":\n",
    "                temp_df = pd.read_csv(path)\n",
    "            elif path.suffix == \".parquet\":\n",
    "                temp_df = pd.read_parquet(path)\n",
    "            df = pd.concat([df, temp_df], axis=0)\n",
    "\n",
    "        # Save data to target_path:\n",
    "        df.to_csv(target_path, index=False)\n",
    "        logger.info(f\"Data saved to {target_path}\")\n",
    "\n",
    "# src/data/data_ingestion.py\n",
    "class PolarsDataIngestionStrategy(DataIngestionStrategy):\n",
    "    \"\"\"\n",
    "    Data ingestion strategy using Polars.\n",
    "    \"\"\"\n",
    "    def ingest_data(self, paths: list, target_path: Path) -> None:\n",
    "        \"\"\"\n",
    "        Ingests data using Polars.\n",
    "\n",
    "        Args:\n",
    "            paths (list): List of file paths to ingest data from.\n",
    "            target_path (Path): Path to save the ingested data.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        df = None\n",
    "\n",
    "        # Read and concatenate lazyframes (if more than one):\n",
    "        for path in paths:\n",
    "            path = Path(path)\n",
    "            start = time.perf_counter()\n",
    "            if path.suffix == \".csv\":\n",
    "                temp_df = pl.scan_csv(path)\n",
    "            elif path.suffix == \".parquet\":\n",
    "                temp_df = pl.scan_parquet(path)\n",
    "            if df is None:\n",
    "                df = temp_df\n",
    "            else:\n",
    "                df = pl.concat([df, temp_df], how=\"vertical\")\n",
    "\n",
    "        # Save data to target_path:\n",
    "        df.sink_csv(target_path, index=False)\n",
    "        logger.info(f\"Data saved to {target_path}\")\n",
    "\n",
    "# src/data/data_ingestion.py\n",
    "class DataIngestion:\n",
    "    \"\"\"\n",
    "    Class to manage data ingestion process.\n",
    "    \"\"\"\n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        \"\"\"\n",
    "        Instantiate `DataIngestion` class.\n",
    "\n",
    "        Args:\n",
    "            config (DataIngestionConfig): Configuration for data ingestion.\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "\n",
    "    def ingest_data(self, strategy: DataIngestionStrategy) -> None:\n",
    "        \"\"\"\n",
    "        Ingests data using the specified strategy.\n",
    "\n",
    "        Args:\n",
    "            strategy (DataIngestionStrategy): Strategy to use for data ingestion.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Check if the path is a string or list of paths:\n",
    "            paths = self.config.source_path if isinstance(self.config.source_path, list) else [self.config.source_path]\n",
    "            logger.info(\"Ingest data\")\n",
    "            strategy.ingest_data(paths, self.config.target_path)\n",
    "            logger.info(f\"Successfully ingest data using {strategy.__class__.__name__}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during data ingestion: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-05 14:09:47,864 - credit-scorecard-logger - INFO - yaml file: config.yaml loaded successfully\n",
      "2024-06-05 14:09:47,868 - credit-scorecard-logger - INFO - yaml file: params.yaml loaded successfully\n",
      "2024-06-05 14:09:47,872 - credit-scorecard-logger - INFO - yaml file: schema.yaml loaded successfully\n",
      "2024-06-05 14:09:47,874 - credit-scorecard-logger - INFO - Created directory at: artifacts\n",
      "2024-06-05 14:09:47,875 - credit-scorecard-logger - INFO - Created directory at: artifacts/data_ingestion\n",
      "2024-06-05 14:09:48,067 - credit-scorecard-logger - INFO - Data saved to artifacts\\data_ingestion\\credit_risk_dataset.csv\n",
      "2024-06-05 14:09:48,068 - credit-scorecard-logger - INFO - Successfully ingested data using PandasDataIngestionStrategy\n"
     ]
    }
   ],
   "source": [
    "from src.config.configuration_manager import ConfigurationManager\n",
    "from src.data.data_ingestion import DataIngestion\n",
    "from src.data.data_ingestion import PandasDataIngestionStrategy\n",
    "\n",
    "try:\n",
    "    configuration_manager = ConfigurationManager()\n",
    "    data_ingestion = DataIngestion( \n",
    "        config=configuration_manager.get_data_ingestion_config()\n",
    "    )\n",
    "    data_ingestion.ingest_data(strategy=PandasDataIngestionStrategy())\n",
    "except Exception as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "Restart and run again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-05 14:10:57,823 - credit-scorecard-logger - INFO - >>>>>> Data Ingestion Stage Started <<<<<<\n",
      "2024-06-05 14:10:57,829 - credit-scorecard-logger - INFO - yaml file: config.yaml loaded successfully\n",
      "2024-06-05 14:10:57,832 - credit-scorecard-logger - INFO - yaml file: params.yaml loaded successfully\n",
      "2024-06-05 14:10:57,837 - credit-scorecard-logger - INFO - yaml file: schema.yaml loaded successfully\n",
      "2024-06-05 14:10:57,839 - credit-scorecard-logger - INFO - Created directory at: artifacts\n",
      "2024-06-05 14:10:57,845 - credit-scorecard-logger - INFO - yaml file: config.yaml loaded successfully\n",
      "2024-06-05 14:10:57,850 - credit-scorecard-logger - INFO - yaml file: params.yaml loaded successfully\n",
      "2024-06-05 14:10:57,856 - credit-scorecard-logger - INFO - yaml file: schema.yaml loaded successfully\n",
      "2024-06-05 14:10:57,857 - credit-scorecard-logger - INFO - Created directory at: artifacts\n",
      "2024-06-05 14:10:57,859 - credit-scorecard-logger - INFO - Created directory at: artifacts/data_ingestion\n",
      "2024-06-05 14:10:58,042 - credit-scorecard-logger - INFO - Data saved to artifacts\\data_ingestion\\credit_risk_dataset.csv\n",
      "2024-06-05 14:10:58,043 - credit-scorecard-logger - INFO - Successfully ingested data using PandasDataIngestionStrategy\n",
      "2024-06-05 14:10:58,044 - credit-scorecard-logger - INFO - >>>>>> Data Ingestion Stage Completed <<<<<<\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from src.utils.common import logger\n",
    "from src.config.configuration_manager import ConfigurationManager\n",
    "from src.data.data_ingestion import DataIngestion\n",
    "from src.data.data_ingestion import PandasDataIngestionStrategy\n",
    "\n",
    "# src/pipelines/data_ingestion.py\n",
    "class DataIngestionPipeline:\n",
    "    \"\"\"\n",
    "    Class to manage the data ingestion training pipeline.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Instantiate `DataIngestionPipeline` class.\n",
    "        \"\"\"\n",
    "        self.configuration_manager = ConfigurationManager()\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Ingest data using the Pandas data ingestion strategy.\n",
    "        \"\"\"\n",
    "        configuration_manager = ConfigurationManager()\n",
    "        data_ingestion = DataIngestion(\n",
    "            config=configuration_manager.get_data_ingestion_config()\n",
    "        )\n",
    "        data_ingestion.ingest_data(strategy=PandasDataIngestionStrategy())\n",
    "\n",
    "\n",
    "STAGE_NAME = \"Data Ingestion Stage\"\n",
    "try:\n",
    "    logger.info(f\">>>>>> {STAGE_NAME} Started <<<<<<\")\n",
    "    data_ingestion_training_pipeline = DataIngestionPipeline()\n",
    "    data_ingestion_training_pipeline.run()\n",
    "    logger.info(f\">>>>>> {STAGE_NAME} Completed <<<<<<\")\n",
    "except Exception as e:\n",
    "    logger.error(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "risk-modelling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
