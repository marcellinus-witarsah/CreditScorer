{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training Pipeline Development\n",
    "- Author: Marcellinus Aditya Witarsah\n",
    "- Date: 05 June 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import logging\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "from pathlib import Path\n",
    "from abc import ABC\n",
    "from abc import abstractmethod\n",
    "from scipy import stats\n",
    "from typing import Tuple\n",
    "from typing import Union\n",
    "from dataclasses import dataclass\n",
    "from src.utils.common import logger\n",
    "from src.utils.common import read_yaml, create_directories\n",
    "from src.constants import CONFIG_FILE_PATH, SCHEMA_FILE_PATH, PARAMS_FILE_PATH\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from optbinning import Scorecard\n",
    "from optbinning import BinningProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run once only\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/entities/config_entity.py\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainingConfig:\n",
    "    \"\"\"\n",
    "    Data class for storing model training configuration.\n",
    "\n",
    "    Attributes:\n",
    "        root_dir (Path): Root directory for model training.\n",
    "        train_data_path (Path): Path to the training data.\n",
    "        model_path (Path): Path to save the trained model.\n",
    "        target_column (str): The name of the target column.\n",
    "        BinningProcess (dict): Configuration for the binning process.\n",
    "        LogisticRegression (dict): Configuration for logistic regression.\n",
    "        Scorecard (dict): Configuration for the scorecard.\n",
    "    \"\"\"\n",
    "    root_dir: Path\n",
    "    train_data_path: Path\n",
    "    model_path: Path\n",
    "    target_column: str\n",
    "    BinningProcess: dict\n",
    "    LogisticRegression: dict\n",
    "    Scorecard: dict\n",
    "\n",
    "# src/config/configuration_manager.py\n",
    "class ConfigurationManager:\n",
    "    \"\"\"\n",
    "    Prepare ConfigurationManager class.\n",
    "    \n",
    "    This class is responsible for reading configuration files and preparing\n",
    "    configuration settings for the pipeline.\n",
    "\n",
    "    Attributes:\n",
    "        config (dict): Parsed configuration file content.\n",
    "        params (dict): Parsed parameters file content.\n",
    "        schema (dict): Parsed schema file content.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath: str = CONFIG_FILE_PATH, \n",
    "        params_filepath: str = PARAMS_FILE_PATH, \n",
    "        schema_filepath: str = SCHEMA_FILE_PATH\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the ConfigurationManager with file paths.\n",
    "\n",
    "        Args:\n",
    "            config_filepath (str): File path to the configuration YAML file.\n",
    "            params_filepath (str): File path to the parameters YAML file.\n",
    "            schema_filepath (str): File path to the schema YAML file.\n",
    "        \"\"\"\n",
    "        self.config = read_yaml(Path(config_filepath))\n",
    "        self.params = read_yaml(Path(params_filepath))\n",
    "        self.schema = read_yaml(Path(schema_filepath))\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_training_config(self) -> ModelTrainingConfig:\n",
    "        \"\"\"\n",
    "        Get configuration for model training.\n",
    "        \n",
    "        Returns:\n",
    "            ModelTrainingConfig: Configuration for model training.\n",
    "        \"\"\"\n",
    "        config = self.config.model_training\n",
    "        params = self.params\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_training_config = ModelTrainingConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            train_data_path=config.train_data_path,\n",
    "            model_path=config.model_path,\n",
    "            target_column=params.data_preprocessing.split_data.target_column,\n",
    "            BinningProcess=params.BinningProcess,\n",
    "            LogisticRegression=params.LogisticRegression,\n",
    "            Scorecard=params.Scorecard,\n",
    "        )\n",
    "        return model_training_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-05 15:58:54,109 - credit-scorecard-logger - INFO - yaml file: config.yaml loaded successfully\n",
      "2024-06-05 15:58:54,113 - credit-scorecard-logger - INFO - yaml file: params.yaml loaded successfully\n",
      "2024-06-05 15:58:54,116 - credit-scorecard-logger - INFO - yaml file: schema.yaml loaded successfully\n",
      "2024-06-05 15:58:54,117 - credit-scorecard-logger - INFO - Created directory at: artifacts\n",
      "2024-06-05 15:58:54,119 - credit-scorecard-logger - INFO - Created directory at: artifacts/model_training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModelTrainingConfig(root_dir='artifacts/model_training', train_data_path='artifacts/data_preprocessing/train.csv', model_path='artifacts/model_training/model.pkl', target_column='loan_status', BinningProcess=ConfigBox({'categorical_variables': ['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file'], 'selection_criteria': {'iv': {'min': 0.02, 'max': 1}}}), LogisticRegression=ConfigBox({'random_state': 42}), Scorecard=ConfigBox({'scaling_method': 'pdo_odds', 'scaling_method_params': {'pdo': 20, 'odds': 1, 'scorecard_points': 500}, 'intercept_based': True}))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration_manager = ConfigurationManager()\n",
    "configuration_manager.get_model_training_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from typing import Tuple\n",
    "\n",
    "# src/data/model_training.py\n",
    "class ModelTraining:\n",
    "    \"\"\"\n",
    "    Class to handle the model training process.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: ModelTrainingConfig):\n",
    "        \"\"\"\n",
    "        Instantiate `ModelTraining` class.\n",
    "\n",
    "        Args:\n",
    "            config (ModelTrainingConfig): Configuration for model training.\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "\n",
    "    def train(self) -> None:\n",
    "        \"\"\"\n",
    "        Train and save the model.\n",
    "        \"\"\"\n",
    "        logger.info(\"Train model\")\n",
    "        train = pd.read_csv(self.config.train_data_path) \n",
    "\n",
    "        X_train = train.drop(columns=[self.config.target_column])\n",
    "        y_train = train[self.config.target_column]\n",
    "\n",
    "        # Instantiate BinningProcess\n",
    "        binning_process = BinningProcess(\n",
    "            X_train.columns.values, \n",
    "            **self.config.BinningProcess\n",
    "        )\n",
    "        # Instantiate LogisticRegression\n",
    "        logreg_model = LogisticRegression(**self.config.LogisticRegression) \n",
    "\n",
    "        # Instantiate Scorecard Model\n",
    "        scorecard = Scorecard(\n",
    "            binning_process=binning_process,\n",
    "            estimator=logreg_model,\n",
    "            **self.config.Scorecard\n",
    "        )\n",
    "\n",
    "        # Train\n",
    "        scorecard.fit(X_train, y_train)\n",
    "\n",
    "        # Save model\n",
    "        scorecard.save(self.config.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-05 16:00:31,292 - credit-scorecard-logger - INFO - yaml file: config.yaml loaded successfully\n",
      "2024-06-05 16:00:31,296 - credit-scorecard-logger - INFO - yaml file: params.yaml loaded successfully\n",
      "2024-06-05 16:00:31,300 - credit-scorecard-logger - INFO - yaml file: schema.yaml loaded successfully\n",
      "2024-06-05 16:00:31,301 - credit-scorecard-logger - INFO - Created directory at: artifacts\n",
      "2024-06-05 16:00:31,302 - credit-scorecard-logger - INFO - Created directory at: artifacts/model_training\n",
      "2024-06-05 16:00:31,303 - credit-scorecard-logger - INFO - Train model\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    configuration_manager = ConfigurationManager()\n",
    "    model_training = ModelTraining( \n",
    "        config=configuration_manager.get_model_training_config()\n",
    "    )\n",
    "    model_training.train()\n",
    "except Exception as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "Restart and run again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-05 16:13:33,295 - credit-scorecard-logger - INFO - >>>>>> Model Training Stage Started <<<<<<\n",
      "2024-06-05 16:13:33,301 - credit-scorecard-logger - INFO - yaml file: config.yaml loaded successfully\n",
      "2024-06-05 16:13:33,308 - credit-scorecard-logger - INFO - yaml file: params.yaml loaded successfully\n",
      "2024-06-05 16:13:33,312 - credit-scorecard-logger - INFO - yaml file: schema.yaml loaded successfully\n",
      "2024-06-05 16:13:33,314 - credit-scorecard-logger - INFO - Created directory at: artifacts\n",
      "2024-06-05 16:13:33,315 - credit-scorecard-logger - INFO - Created directory at: artifacts/model_training\n",
      "2024-06-05 16:13:33,317 - credit-scorecard-logger - INFO - Train model\n",
      "2024-06-05 16:13:34,406 - credit-scorecard-logger - INFO - >>>>>> Model Training Stage Completed <<<<<<\n"
     ]
    }
   ],
   "source": [
    "from src.utils.common import logger\n",
    "from src.config.configuration_manager import ConfigurationManager\n",
    "from src.models.model_training import ModelTraining\n",
    "\n",
    "class ModelTrainingPipeline:\n",
    "    \"\"\"\n",
    "    Class to manage the model training pipeline.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Instantiate `ModelTrainingPipeline` class.\n",
    "        \"\"\"\n",
    "        self.configuration_manager = ConfigurationManager()\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Execute the model training process.\n",
    "        \"\"\"\n",
    "        model_training = ModelTraining(\n",
    "            config=self.configuration_manager.get_model_training_config()\n",
    "        )\n",
    "        model_training.train()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    STAGE_NAME = \"Model Training Stage\"\n",
    "    try:\n",
    "        logger.info(f\">>>>>> {STAGE_NAME} Started <<<<<<\")\n",
    "        model_training_pipeline = ModelTrainingPipeline()\n",
    "        model_training_pipeline.run()\n",
    "        logger.info(f\">>>>>> {STAGE_NAME} Completed <<<<<<\")\n",
    "    except Exception as e:\n",
    "        logger.error(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "risk-modelling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
