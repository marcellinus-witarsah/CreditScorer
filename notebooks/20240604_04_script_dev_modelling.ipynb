{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training Pipeline Development\n",
    "- Author: Marcellinus Aditya Witarsah\n",
    "- Date: 05 June 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CVXPY) Jun 08 01:35:06 PM: Encountered unexpected exception importing solver GLOP:\n",
      "RuntimeError('Unrecognized new version of ortools (9.10.4067). Expected < 9.10.0. Please open a feature request on cvxpy to enable support for this version.')\n",
      "(CVXPY) Jun 08 01:35:06 PM: Encountered unexpected exception importing solver PDLP:\n",
      "RuntimeError('Unrecognized new version of ortools (9.10.4067). Expected < 9.10.0. Please open a feature request on cvxpy to enable support for this version.')\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import logging\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from abc import ABC\n",
    "from abc import abstractmethod\n",
    "from scipy import stats\n",
    "from typing import Tuple\n",
    "from typing import Union\n",
    "from dataclasses import dataclass\n",
    "from src.utils.common import logger\n",
    "from src.utils.common import read_yaml, create_directories\n",
    "from src.constants import CONFIG_FILE_PATH, SCHEMA_FILE_PATH, PARAMS_FILE_PATH\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from optbinning import Scorecard\n",
    "from optbinning import BinningProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run once only\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainingConfig:\n",
    "    \"\"\"\n",
    "    Data class for storing model training configuration.\n",
    "\n",
    "    Attributes:\n",
    "        root_dir (str): Root directory for model training.\n",
    "        model_path (str): Path to save the trained model.\n",
    "        train_data_path (str): Path to the training data.\n",
    "        test_data_path (str): Path to the test data.\n",
    "        experiment_name (str): Name of the experiment.\n",
    "        run_name (str): Name of the run.\n",
    "        target_column (str): The name of the target column.\n",
    "        binning_process (dict): Configuration for the binning process.\n",
    "        logistic_regression (dict): Configuration for logistic regression.\n",
    "        scorecard (dict): Configuration for the scorecard.\n",
    "    \"\"\"\n",
    "    root_dir: str\n",
    "    model_path: str\n",
    "    train_data_path: str\n",
    "    test_data_path: str\n",
    "    experiment_name: str\n",
    "    run_name: str\n",
    "    target_column: str\n",
    "    binning_process: dict\n",
    "    logistic_regression: dict\n",
    "    scorecard: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/config/configuration_manager.py\n",
    "from src.utils.common import read_yaml, create_directories\n",
    "class ConfigurationManager:\n",
    "    \"\"\"\n",
    "    Prepare ConfigurationManager class.\n",
    "    \n",
    "    This class is responsible for reading configuration files and preparing\n",
    "    configuration settings for the pipeline.\n",
    "\n",
    "    Attributes:\n",
    "        config (dict): Parsed configuration file content.\n",
    "        params (dict): Parsed parameters file content.\n",
    "        schema (dict): Parsed schema file content.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath: str = CONFIG_FILE_PATH, \n",
    "        params_filepath: str = PARAMS_FILE_PATH, \n",
    "        schema_filepath: str = SCHEMA_FILE_PATH\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the ConfigurationManager with file paths.\n",
    "\n",
    "        Args:\n",
    "            config_filepath (str): File path to the configuration YAML file.\n",
    "            params_filepath (str): File path to the parameters YAML file.\n",
    "            schema_filepath (str): File path to the schema YAML file.\n",
    "        \"\"\"\n",
    "        self.config = read_yaml(Path(config_filepath))\n",
    "        self.params = read_yaml(Path(params_filepath))\n",
    "        self.schema = read_yaml(Path(schema_filepath))\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_training_config(self) -> ModelTrainingConfig:\n",
    "        \"\"\"\n",
    "        Get configuration for model training.\n",
    "        \n",
    "        Returns:\n",
    "            ModelTrainingConfig: Configuration for model training.\n",
    "        \"\"\"\n",
    "        config = self.config.model_training\n",
    "        params = self.params\n",
    "        schema = self.schema.TARGET_COLUMN\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_training_config = ModelTrainingConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            model_path=config.model_path,\n",
    "            train_data_path=config.train_data_path,\n",
    "            test_data_path=config.test_data_path,\n",
    "            experiment_name=config.experiment_name,\n",
    "            run_name=config.run_name,\n",
    "            target_column=schema.name,\n",
    "            binning_process=params.binning_process,\n",
    "            logistic_regression=params.logistic_regression,\n",
    "            scorecard=params.scorecard,\n",
    "        )\n",
    "        return model_training_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-08 13:35:13,457 - credit-scorecard-logger - INFO - yaml file: config.yaml loaded successfully\n",
      "2024-06-08 13:35:13,468 - credit-scorecard-logger - INFO - yaml file: params.yaml loaded successfully\n",
      "2024-06-08 13:35:13,471 - credit-scorecard-logger - INFO - yaml file: schema.yaml loaded successfully\n",
      "2024-06-08 13:35:13,471 - credit-scorecard-logger - INFO - Created directory at: artifacts\n",
      "2024-06-08 13:35:13,472 - credit-scorecard-logger - INFO - Created directory at: artifacts/model_training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModelTrainingConfig(root_dir='artifacts/model_training', model_path='artifacts/model_training/model.joblib', train_data_path='artifacts/data_preprocessing/train.csv', test_data_path='artifacts/data_preprocessing/test.csv', experiment_name='credit-scorecard', run_name='woe-logreg-scorecard-model', target_column='loan_status', binning_process=ConfigBox({'categorical_variables': ['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file'], 'selection_criteria': {'iv': {'min': 0.02, 'max': 1}}}), logistic_regression=ConfigBox({'random_state': 42}), scorecard=ConfigBox({'scaling_method': 'pdo_odds', 'scaling_method_params': {'pdo': 20, 'odds': 1, 'scorecard_points': 500}, 'intercept_based': True}))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration_manager = ConfigurationManager()\n",
    "configuration_manager.get_model_training_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc, precision_recall_curve\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "def roc_auc(y_true: Union[list, np.array], y_pred_proba: Union[list, np.array]) -> float:\n",
    "    \"\"\"\n",
    "    Calculate ROC AUC (Area Under the Receiver Operating Characteristic Curve).\n",
    "    \n",
    "    Args:\n",
    "        y_true (Union[list, np.array]): True labels.\n",
    "        y_pred_prob (Union[list, np.array]): Prediction probability of target class of `1`\n",
    "    Returns:\n",
    "        float: ROC AUC score.\n",
    "    \"\"\"\n",
    "    return roc_auc_score(y_true, y_pred_proba)\n",
    "\n",
    "def pr_auc(y_true: Union[list, np.array], y_pred_proba: Union[list, np.array]) -> float:\n",
    "    \"\"\"\n",
    "    Calculate PR AUC (Area Under the Precision Recall Curve).\n",
    "    \n",
    "    Args:\n",
    "        y_true (Union[list, np.array]): True labels.\n",
    "        y_pred_prob (Union[list, np.array]): Prediction probability of target class of `1`\n",
    "    Returns:\n",
    "        float: PR AUC score.\n",
    "    \"\"\"\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred_proba)\n",
    "    return auc(recall, precision)\n",
    "\n",
    "def gini(y_true: Union[list, np.array], y_pred_proba: Union[list, np.array]) -> float:\n",
    "    \"\"\"\n",
    "    Calculate Gini coefficient.\n",
    "\n",
    "    Args:\n",
    "        y_true (Union[list, np.array]): True labels.\n",
    "        y_pred_prob (Union[list, np.array]): Prediction probability of target class of `1`\n",
    "    Returns:\n",
    "        float: Gini coefficient.\n",
    "    \"\"\"\n",
    "    return 2 * roc_auc_score(y_true, y_pred_proba) - 1\n",
    "\n",
    "def ks(y_true: Union[list, np.array], y_pred_proba: Union[list, np.array]) -> float:\n",
    "    \"\"\"\n",
    "    Calculate Kolmogorov-Smirnov (KS) statistic.\n",
    "\n",
    "    Args:\n",
    "        y_true (Union[list, np.array]): True labels.\n",
    "        y_pred_prob (Union[list, np.array]): Prediction probability of target class of `1`\n",
    "    Returns:\n",
    "        float: KS statistic.\n",
    "    \"\"\"\n",
    "    y_pred_proba_not_default = y_pred_proba[y_true == 0]\n",
    "    y_pred_proba_default = y_pred_proba[y_true == 1]\n",
    "    ks_stat, _ = ks_2samp(y_pred_proba_not_default, y_pred_proba_default)\n",
    "    return ks_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "def plot_calibration_curve(y_true: np.array, y_pred_proba: np.array, model_name: str, figsize: Tuple[int, int], path: Path, n_bins=10) -> plt.Axes:\n",
    "    \"\"\"\n",
    "    Plot calibration curve.\n",
    "\n",
    "    Args:\n",
    "        y_pred_proba (np.array): Predicted probabilities for the positive class (default).\n",
    "        y_true (np.array): True binary labels (0 for not default, 1 for default).\n",
    "        model_name (str): Name of the model for labeling the plot.\n",
    "        figsize (Tuple[int, int]): size of the plot.\n",
    "        n_bins (int): Number of bins to use for calibration curve.\n",
    "    Return:\n",
    "        plt.Axes: Matplotlib axis object.\n",
    "    \"\"\"\n",
    "    prob_true, prob_pred = calibration_curve(y_true, y_pred_proba, n_bins=n_bins)\n",
    "    \n",
    "    plt.style.use('fivethirtyeight')\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.plot([0, 1], [0, 1], linestyle='--', label='Perfectly calibrated')\n",
    "    ax.plot(prob_pred, prob_true, marker='o', label=model_name)\n",
    "    ax.set_xlabel('Mean predicted probability')\n",
    "    ax.set_ylabel('Fraction of positives')\n",
    "    ax.set_title('Calibration plot')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "        \n",
    "    image = fig\n",
    "\n",
    "    # Save figure\n",
    "    fig.savefig(path)\n",
    "\n",
    "    # Close plot\n",
    "    plt.close(fig)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from typing import Tuple\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import mlflow\n",
    "from urllib.parse import urlparse\n",
    "from mlflow.models import infer_signature\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "class ModelTraining:\n",
    "    \"\"\"\n",
    "    Class to handle the model training process.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: ModelTrainingConfig):\n",
    "        \"\"\"\n",
    "        Instantiate `ModelTraining` class.\n",
    "\n",
    "        Args:\n",
    "            config (ModelTrainingConfig): Configuration for model training.\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "\n",
    "    def train(self) -> None:\n",
    "        \"\"\"\n",
    "            Train, evaluate, and log model to MLFlow Registry.\n",
    "        \"\"\"\n",
    "        logger.info(\"Train model\")\n",
    "        train = pd.read_csv(self.config.train_data_path)\n",
    "        X_train = train.drop(columns=[self.config.target_column])\n",
    "        y_train = train[self.config.target_column]\n",
    "\n",
    "\n",
    "        # Instantiate BinningProcess:\n",
    "        binning_process = BinningProcess(\n",
    "            X_train.columns.values, \n",
    "            **self.config.binning_process\n",
    "        )\n",
    "\n",
    "        # Instantiate LogisticRegression:\n",
    "        logreg_model = LogisticRegression(**self.config.logistic_regression) \n",
    "\n",
    "        # Instantiate Scorecard:\n",
    "        scorecard_model = Scorecard(\n",
    "            binning_process=binning_process,\n",
    "            estimator=logreg_model,\n",
    "            **self.config.scorecard\n",
    "        )\n",
    "\n",
    "        # Train:\n",
    "        scorecard_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predictin on Train Data:\n",
    "        y_pred_proba_train = scorecard_model.predict_proba(X_train)[:, -1] \n",
    "\n",
    "        # Predictin on Test Data:\n",
    "        test = pd.read_csv(self.config.test_data_path)\n",
    "        X_test = test.drop(columns=[self.config.target_column])\n",
    "        y_test = test[self.config.target_column]\n",
    "        y_pred_proba_test = scorecard_model.predict_proba(X_test)[:, -1] \n",
    "\n",
    "        # Track Experiment using MLFlow:\n",
    "        logger.info(\"Initialize MLFlow Tracking ...\")\n",
    "        mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRAKING_URI\"))\n",
    "        mlflow.set_experiment(self.config.experiment_name)\n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "        logger.info(\"Start Tracking ...\")\n",
    "        # Track Experiment:\n",
    "        with mlflow.start_run(run_name=self.config.run_name):\n",
    "            logger.info(\"Log Params\")\n",
    "            mlflow.log_params(self.config.binning_process)\n",
    "            mlflow.log_params(self.config.logistic_regression)\n",
    "            mlflow.log_params(self.config.scorecard)\n",
    "\n",
    "            # Log Train Metrics\n",
    "            logger.info(\"Log Metrics\")\n",
    "            mlflow.log_metric(\"train_roc_auc\", roc_auc(y_train, y_pred_proba_train))\n",
    "            mlflow.log_metric(\"train_pr_auc\", pr_auc(y_train, y_pred_proba_train))\n",
    "            mlflow.log_metric(\"train_gini\", gini(y_train, y_pred_proba_train))\n",
    "            mlflow.log_metric(\"train_ks\", ks(y_train, y_pred_proba_train))\n",
    "\n",
    "            # log Test Metrics:\n",
    "            mlflow.log_metric(\"test_roc_auc\", roc_auc(y_test, y_pred_proba_test))\n",
    "            mlflow.log_metric(\"test_pr_auc\", pr_auc(y_test, y_pred_proba_test))\n",
    "            mlflow.log_metric(\"test_gini\", gini(y_test, y_pred_proba_test))\n",
    "            mlflow.log_metric(\"test_ks\", ks(y_test, y_pred_proba_test))\n",
    "\n",
    "            # Log Models:\n",
    "            logger.info(\"Log Models\")\n",
    "            signature = infer_signature(X_train.iloc[:1, :], y_pred_proba_train[:1])\n",
    "            mlflow.sklearn.log_model(\n",
    "                scorecard_model, \n",
    "                \"model\",\n",
    "                signature=signature,\n",
    "                registered_model_name=\"credit-score-model\",\n",
    "            )\n",
    "\n",
    "            # Log Plots:\n",
    "            logger.info(\"Log Artifacts\")\n",
    "            image = plot_calibration_curve(y_train, y_pred_proba_train, \"Logistic Regression\", (10, 7), self.config.root_dir+\"/train_model_calibration.png\")\n",
    "            mlflow.log_artifact(self.config.root_dir+\"/train_model_calibration.png\")\n",
    "            image = plot_calibration_curve(y_test, y_pred_proba_test, \"Logistic Regression\", (10, 7), self.config.root_dir+\"/test_model_calibration.png\")\n",
    "            mlflow.log_artifact(self.config.root_dir+\"/test_model_calibration.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-08 13:35:20,247 - credit-scorecard-logger - INFO - yaml file: config.yaml loaded successfully\n",
      "2024-06-08 13:35:20,250 - credit-scorecard-logger - INFO - yaml file: params.yaml loaded successfully\n",
      "2024-06-08 13:35:20,252 - credit-scorecard-logger - INFO - yaml file: schema.yaml loaded successfully\n",
      "2024-06-08 13:35:20,252 - credit-scorecard-logger - INFO - Created directory at: artifacts\n",
      "2024-06-08 13:35:20,252 - credit-scorecard-logger - INFO - Created directory at: artifacts/model_training\n",
      "2024-06-08 13:35:20,252 - credit-scorecard-logger - INFO - Train model\n",
      "2024-06-08 13:35:21,291 - credit-scorecard-logger - INFO - Initialize MLFlow Tracking ...\n",
      "2024-06-08 13:35:21,829 - credit-scorecard-logger - INFO - Start Tracking ...\n",
      "2024-06-08 13:35:22,534 - credit-scorecard-logger - INFO - Log Params\n",
      "2024-06-08 13:35:23,680 - credit-scorecard-logger - INFO - Log Metrics\n",
      "2024-06-08 13:35:27,201 - credit-scorecard-logger - INFO - Log Models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\risk-modelling\\lib\\site-packages\\mlflow\\types\\utils.py:394: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Successfully registered model 'credit-score-model'.\n",
      "2024/06/08 13:35:43 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: credit-score-model, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-08 13:35:43,065 - credit-scorecard-logger - INFO - Log Artifacts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'credit-score-model'.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    configuration_manager = ConfigurationManager()\n",
    "    model_training = ModelTraining( \n",
    "        config=configuration_manager.get_model_training_config()\n",
    "    )\n",
    "    model_training.train()\n",
    "except Exception as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "Restart and run again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-06 16:43:10,142 - credit-scorecard-logger - INFO - >>>>>> Model Training Stage Started <<<<<<\n",
      "2024-06-06 16:43:10,142 - credit-scorecard-logger - INFO - yaml file: config.yaml loaded successfully\n",
      "2024-06-06 16:43:10,154 - credit-scorecard-logger - INFO - yaml file: params.yaml loaded successfully\n",
      "2024-06-06 16:43:10,154 - credit-scorecard-logger - INFO - yaml file: schema.yaml loaded successfully\n",
      "2024-06-06 16:43:10,154 - credit-scorecard-logger - INFO - Created directory at: artifacts\n",
      "2024-06-06 16:43:10,154 - credit-scorecard-logger - INFO - Created directory at: artifacts/model_training\n",
      "2024-06-06 16:43:10,154 - credit-scorecard-logger - INFO - Train model\n",
      "2024-06-06 16:43:11,394 - credit-scorecard-logger - INFO - Initialize MLFlow Tracking ...\n",
      "2024-06-06 16:43:11,808 - credit-scorecard-logger - INFO - Start Tracking ...\n",
      "2024-06-06 16:43:12,527 - credit-scorecard-logger - INFO - Log Params\n",
      "2024-06-06 16:43:13,687 - credit-scorecard-logger - INFO - Log Metrics\n",
      "2024-06-06 16:43:16,902 - credit-scorecard-logger - INFO - Log Models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\923006079\\AppData\\Local\\anaconda3\\envs\\credit-risk-modelling\\lib\\site-packages\\mlflow\\types\\utils.py:394: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Successfully registered model 'WeightOfEvidence+LogisticRegression'.\n",
      "2024/06/06 16:43:44 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: WeightOfEvidence+LogisticRegression, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-06 16:43:44,217 - credit-scorecard-logger - INFO - Log Artifacts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'WeightOfEvidence+LogisticRegression'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-06 16:43:46,873 - credit-scorecard-logger - INFO - >>>>>> Model Training Stage Completed <<<<<<\n"
     ]
    }
   ],
   "source": [
    "from src.utils.common import logger\n",
    "from src.config.configuration_manager import ConfigurationManager\n",
    "from src.models.model_training import ModelTraining\n",
    "\n",
    "class ModelTrainingPipeline:\n",
    "    \"\"\"\n",
    "    Class to manage the model training pipeline.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Instantiate `ModelTrainingPipeline` class.\n",
    "        \"\"\"\n",
    "        self.configuration_manager = ConfigurationManager()\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Execute the model training process.\n",
    "        \"\"\"\n",
    "        model_training = ModelTraining(\n",
    "            config=self.configuration_manager.get_model_training_config()\n",
    "        )\n",
    "        model_training.train()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    STAGE_NAME = \"Model Training Stage\"\n",
    "    try:\n",
    "        logger.info(f\">>>>>> {STAGE_NAME} Started <<<<<<\")\n",
    "        model_training_pipeline = ModelTrainingPipeline()\n",
    "        model_training_pipeline.run()\n",
    "        logger.info(f\">>>>>> {STAGE_NAME} Completed <<<<<<\")\n",
    "    except Exception as e:\n",
    "        logger.error(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "risk-modelling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
